{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"mrunner is a tool intended to run experiment code on different computation systems, without manual deployment and with significantly less configuration. Main features are: prepare remote environment deploy code run experiments use of scheduler, based on mangement of available resources (if remote system supports it) monitor experiments using neptune Currently slurm and kubernetes clusters are supported. It is also possible to run experiment locally.","title":"overview"},{"location":"contribution/","text":"documentation To build and publish documentation use: pip install mkdocs mkdocs build mkdocs gh-pages See mkdocs documentation for more details.","title":"contribution"},{"location":"contribution/#documentation","text":"To build and publish documentation use: pip install mkdocs mkdocs build mkdocs gh-pages See mkdocs documentation for more details.","title":"documentation"},{"location":"dispatcher/","text":"dispatcher Call stack standard_mrunner_main How to debug remarks on current state in neptune.yaml there are placed only tags from python spec function directories Sequence mrunner run with python config eval spec function from python config and list of Experiment classes generate neptune.yaml for each experiment use only: project name, experiment name, parameters, tags, description neptune.yaml files are generated into .... for generating neptune yaml there are required only dictionary with keys: project, name, parameters, [tags], [description] Sequence (old dispatcher) shell script env setup (environment variables + venv activate etc) python dispatcher.py load list of experiments special support for composite experiments register experiments in omninote obtain XRunConfig special support for composite experiments update attributes from command line for each experiment generate neptune yaml name, project parameters: name, type, required, default update experiment structure parameters based on CLI arguments tags generate mrunner cmd depends on XRunType slurm: update env (PLGRID_USERNAME, MRUNNER_SCRATCH_SPACE, PLGRID_HOST) optionally experiments/cmds list is shuffled and/or trimmed to size run experiments it executes set mrunner cmd depends on mrunner backend calls are sync (slurm-srun) or async call (slurm-sbatch, k8s) depends on parallel flag passed in neptune CLI using sequential os.system calls if no parallel call using subprocess.Popen executed by n threads standard_mrunner_main Required enviornment variables which determine method of setting parameters list and experiment directory : key values description MRUNNER_UNDER_NEPTUNE 0/1 both are obtained from neptune PMILOS_DEBUG 0/1 experiment directory passed as cmd argument, parameters evaluated from python file RESOURCE_DIR_PATH path experiment directory pointed by this env var, parameters evaluated from neptune yaml file When experiment is started: under neptune - neptune storage_dir and params are used under PMILOS_DEBUG additional arguments are parsed (same as in original dispatcher.py ) --ex - path to experiment describing python file from which function pointed by --spec is executed; this function shall return structure containing parameters attribute containing experiment parameters --spec - as mentioned above: name of function which returns structure containing parameters list --exp_dir_path - path to experiment directory when both neptune and MRUNNER_DEBUG environment variable are not set --neptune - path to neptune yaml file; paramters are obtained from parameters key and default values are used RESOURCE_DIR_PATH - environment variable pointing path to experiment directory Neptune context obtained in this function is ignored. Experiment dir is also often ignored , except: - model_rl_experiment_loop.py - used to set log dir (see NeptuneLogger) - run_kanapa_ppo.py - used to set env_model_path How to debug TBD","title":"dispatcher"},{"location":"dispatcher/#dispatcher","text":"Call stack standard_mrunner_main How to debug","title":"dispatcher"},{"location":"dispatcher/#remarks-on-current-state","text":"in neptune.yaml there are placed only tags from python spec function","title":"remarks on current state"},{"location":"dispatcher/#directories","text":"","title":"directories"},{"location":"dispatcher/#sequence","text":"mrunner run with python config eval spec function from python config and list of Experiment classes generate neptune.yaml for each experiment use only: project name, experiment name, parameters, tags, description neptune.yaml files are generated into .... for generating neptune yaml there are required only dictionary with keys: project, name, parameters, [tags], [description]","title":"Sequence"},{"location":"dispatcher/#sequence-old-dispatcher","text":"shell script env setup (environment variables + venv activate etc) python dispatcher.py load list of experiments special support for composite experiments register experiments in omninote obtain XRunConfig special support for composite experiments update attributes from command line for each experiment generate neptune yaml name, project parameters: name, type, required, default update experiment structure parameters based on CLI arguments tags generate mrunner cmd depends on XRunType slurm: update env (PLGRID_USERNAME, MRUNNER_SCRATCH_SPACE, PLGRID_HOST) optionally experiments/cmds list is shuffled and/or trimmed to size run experiments it executes set mrunner cmd depends on mrunner backend calls are sync (slurm-srun) or async call (slurm-sbatch, k8s) depends on parallel flag passed in neptune CLI using sequential os.system calls if no parallel call using subprocess.Popen executed by n threads","title":"Sequence (old dispatcher)"},{"location":"dispatcher/#standard_mrunner_main","text":"Required enviornment variables which determine method of setting parameters list and experiment directory : key values description MRUNNER_UNDER_NEPTUNE 0/1 both are obtained from neptune PMILOS_DEBUG 0/1 experiment directory passed as cmd argument, parameters evaluated from python file RESOURCE_DIR_PATH path experiment directory pointed by this env var, parameters evaluated from neptune yaml file When experiment is started: under neptune - neptune storage_dir and params are used under PMILOS_DEBUG additional arguments are parsed (same as in original dispatcher.py ) --ex - path to experiment describing python file from which function pointed by --spec is executed; this function shall return structure containing parameters attribute containing experiment parameters --spec - as mentioned above: name of function which returns structure containing parameters list --exp_dir_path - path to experiment directory when both neptune and MRUNNER_DEBUG environment variable are not set --neptune - path to neptune yaml file; paramters are obtained from parameters key and default values are used RESOURCE_DIR_PATH - environment variable pointing path to experiment directory Neptune context obtained in this function is ignored. Experiment dir is also often ignored , except: - model_rl_experiment_loop.py - used to set log dir (see NeptuneLogger) - run_kanapa_ppo.py - used to set env_model_path","title":"standard_mrunner_main"},{"location":"dispatcher/#how-to-debug","text":"TBD","title":"How to debug"},{"location":"kubernetes/","text":"Kubernetes system may be used to manage computation resources and accordingly schedule experimentation jobs. Read more about Kubernetes objects . Till now kubernetes support was tested only on GKE - thus it may need some code update in order to run on on premise cluster. Setup kubernetes (Need to be followed by other persons to write/check steps) To manage cluster resources and jobs install kubectl tool and setup local docker engine. mrunner and kubectl uses kubectl context, which points to which cluster we'll communicate to. This structure may be configured, by one of below methods: while using google kubernetes cluster (GKE) it is done with gcloud tool - see GKE section for details, while using minikube there is created minikube context during starting local cluster, defining context in YAML config (TBD) there is possiblity to switch between already configured contexts using: commandline kubectl config use-context <context_name> kubectl config current-context # show context which is used kubectl configuration is stored in ~/.kube/config file and can be viewed using: kubectl config view Google Kubernetes Engine (GKE) If you plan to use GKE additionally follow below steps: Install gcloud tool, which will provide authorization to access GKE clusters. It also contain functionality to manage GKE clusters and Google Cloud Storage (GCS). Configure cluster credentials and kubectl context follow below steps: Go to GKE console Select project Press connect button on clusters list Copy and paste gcloud command line Authorize google cloud sdk by obtaining token with: sh gcloud auth application-default login remote context keys for kubernetes Possible remote context keys: key req description example name R unique name of context which identifies him rl.sandbox type R shall equal kubernetes kubernetes storage R path to directory where neptune CLI will store data for experiment provenance (required even when neptune is disabled) /storage registry_url R url to docker image repository where built experiment images will be published (shall be available also from cluster level) https://gcr.io resources O defines resource limits for every experiment (by default no resource limits) {cpu: 4, tpu: 1, mem: 8G} neptune O enable/disable neptune (by default enabled) true google_project_id O if using GKE set this key with google project id rl-sandbox-1234 default_pvc_size O size of storage created for new project (see persistent volumes section; by default creates volume of size KubernetesBackend.DEFAULT_STORAGE_PVC_SIZE ) 100G Run experiment on kubernetes Available options specific for kubernetes cluster: key req description / additional information example config R path to neptune experiment configuration; mrunner uses i.a. project and experiment names, parameters list neptune.yaml base_image R name and tag of base docker image used to build experiment docker image python:3 requirements R path to requirements.txt file with python requirements requirements.txt Sample command call: mrunner run --config neptune.yaml \\ --tags \"grid_search_k-12-48\" --tags new_data \\ --requirements requirements.txt \\ --base_image python:3 experiment1.py -- --param1 1 Another example could be: mrunner --context gke.sandbox run --config neptune.yaml \\ --base_image python:3 \\ --requirements requirements.txt \\ -- experiment1.py -- --epochs 3 Notice (in both examples) that certain flags refer to the mrunner itself (eg. config, base_image) and others to experiment/script that we wish to run (eg. epochs, param1); the way these two sets are separated is relevant ('--'). Context is provided to mrunner before run . While running experiments on kubernetes, mrunner performs following steps: Prepares docker image based on provided in command line parameters see templates/Dockerfile.jinja2 file for details during build docker cache is used, so if there is no change in requirements.txt file, build shall be relatively fast If new image was generated tags it with timestamp and published in docker containers repository. Ensure kubernetes configuration (create resources if missing) namespace named after project name exists; see cluster namespaces section how to switch kubectl between them. persistent volume claim Generate kubernetes job - in fact your experiment Cluster namespaces For each project, new namespace is created in kubernetes cluster. This provide freedom in experiments naming, possibility to manage resource quota per project, separate storage. More details may be found in kubernetes documentation . kubectl tool is required to have pointed default namespaces. Otherwise, we shall pass --namespace|-n option for each kubectl call. To switch kubectl to access given namespace resources by default set kubectl context with: kubectl get namespace kubectl config set-context $(kubectl config current-context) \\ --namespace=<project_based_namespace> Persistent volumes To gather project data from different experiments in single place, it is required to create set of Persistent Volume related resources (see diagram below and nfs example ). During execution of each experiment, it is checked for existance and correctness of this setup. The size of pvc/storage defines default_pvc_size key from mrunner context, but if not provided volume of size KubernetesBackend.DEFAULT_STORAGE_PVC_SIZE (40GB) will be created. By default volume is mounted under directory pointed by path from $STORAGE_DIR environment variable (the same as passed in storage key mrunner context). Kubernetes tools cheat sheet To check with which cluster kubectl is communicating: kubectl config current-context To observe from command line current status of jobs you may use watch 'kubectl get all,pvc,pv -a' watch 'kubectl get all,pvc,pv -a -o wide' watch 'kubectl get all,pvc,pv -a --field-selector=metadata.namespace!=kube-system --all-namespaces' To observe logs from given pod (also completed and failed) you may use: kubectl logs -f <pod_name> In order to connect to running pod use: kubectl attach <pod_name> To delete job from cluster use below command. But be aware that related pod also will be deleted. kubectl delete job <job_name> To show details of job or pod use: kubectl describe <resource_name> To download data from presistent volume use: TBD","title":"kubernetes"},{"location":"kubernetes/#setup-kubernetes","text":"(Need to be followed by other persons to write/check steps) To manage cluster resources and jobs install kubectl tool and setup local docker engine. mrunner and kubectl uses kubectl context, which points to which cluster we'll communicate to. This structure may be configured, by one of below methods: while using google kubernetes cluster (GKE) it is done with gcloud tool - see GKE section for details, while using minikube there is created minikube context during starting local cluster, defining context in YAML config (TBD) there is possiblity to switch between already configured contexts using: commandline kubectl config use-context <context_name> kubectl config current-context # show context which is used kubectl configuration is stored in ~/.kube/config file and can be viewed using: kubectl config view","title":"Setup kubernetes"},{"location":"kubernetes/#google-kubernetes-engine-gke","text":"If you plan to use GKE additionally follow below steps: Install gcloud tool, which will provide authorization to access GKE clusters. It also contain functionality to manage GKE clusters and Google Cloud Storage (GCS). Configure cluster credentials and kubectl context follow below steps: Go to GKE console Select project Press connect button on clusters list Copy and paste gcloud command line Authorize google cloud sdk by obtaining token with: sh gcloud auth application-default login","title":"Google Kubernetes Engine (GKE)"},{"location":"kubernetes/#remote-context-keys-for-kubernetes","text":"Possible remote context keys: key req description example name R unique name of context which identifies him rl.sandbox type R shall equal kubernetes kubernetes storage R path to directory where neptune CLI will store data for experiment provenance (required even when neptune is disabled) /storage registry_url R url to docker image repository where built experiment images will be published (shall be available also from cluster level) https://gcr.io resources O defines resource limits for every experiment (by default no resource limits) {cpu: 4, tpu: 1, mem: 8G} neptune O enable/disable neptune (by default enabled) true google_project_id O if using GKE set this key with google project id rl-sandbox-1234 default_pvc_size O size of storage created for new project (see persistent volumes section; by default creates volume of size KubernetesBackend.DEFAULT_STORAGE_PVC_SIZE ) 100G","title":"remote context keys for kubernetes"},{"location":"kubernetes/#run-experiment-on-kubernetes","text":"Available options specific for kubernetes cluster: key req description / additional information example config R path to neptune experiment configuration; mrunner uses i.a. project and experiment names, parameters list neptune.yaml base_image R name and tag of base docker image used to build experiment docker image python:3 requirements R path to requirements.txt file with python requirements requirements.txt Sample command call: mrunner run --config neptune.yaml \\ --tags \"grid_search_k-12-48\" --tags new_data \\ --requirements requirements.txt \\ --base_image python:3 experiment1.py -- --param1 1 Another example could be: mrunner --context gke.sandbox run --config neptune.yaml \\ --base_image python:3 \\ --requirements requirements.txt \\ -- experiment1.py -- --epochs 3 Notice (in both examples) that certain flags refer to the mrunner itself (eg. config, base_image) and others to experiment/script that we wish to run (eg. epochs, param1); the way these two sets are separated is relevant ('--'). Context is provided to mrunner before run . While running experiments on kubernetes, mrunner performs following steps: Prepares docker image based on provided in command line parameters see templates/Dockerfile.jinja2 file for details during build docker cache is used, so if there is no change in requirements.txt file, build shall be relatively fast If new image was generated tags it with timestamp and published in docker containers repository. Ensure kubernetes configuration (create resources if missing) namespace named after project name exists; see cluster namespaces section how to switch kubectl between them. persistent volume claim Generate kubernetes job - in fact your experiment","title":"Run experiment on kubernetes"},{"location":"kubernetes/#cluster-namespaces","text":"For each project, new namespace is created in kubernetes cluster. This provide freedom in experiments naming, possibility to manage resource quota per project, separate storage. More details may be found in kubernetes documentation . kubectl tool is required to have pointed default namespaces. Otherwise, we shall pass --namespace|-n option for each kubectl call. To switch kubectl to access given namespace resources by default set kubectl context with: kubectl get namespace kubectl config set-context $(kubectl config current-context) \\ --namespace=<project_based_namespace>","title":"Cluster namespaces"},{"location":"kubernetes/#persistent-volumes","text":"To gather project data from different experiments in single place, it is required to create set of Persistent Volume related resources (see diagram below and nfs example ). During execution of each experiment, it is checked for existance and correctness of this setup. The size of pvc/storage defines default_pvc_size key from mrunner context, but if not provided volume of size KubernetesBackend.DEFAULT_STORAGE_PVC_SIZE (40GB) will be created. By default volume is mounted under directory pointed by path from $STORAGE_DIR environment variable (the same as passed in storage key mrunner context).","title":"Persistent volumes"},{"location":"kubernetes/#kubernetes-tools-cheat-sheet","text":"To check with which cluster kubectl is communicating: kubectl config current-context To observe from command line current status of jobs you may use watch 'kubectl get all,pvc,pv -a' watch 'kubectl get all,pvc,pv -a -o wide' watch 'kubectl get all,pvc,pv -a --field-selector=metadata.namespace!=kube-system --all-namespaces' To observe logs from given pod (also completed and failed) you may use: kubectl logs -f <pod_name> In order to connect to running pod use: kubectl attach <pod_name> To delete job from cluster use below command. But be aware that related pod also will be deleted. kubectl delete job <job_name> To show details of job or pod use: kubectl describe <resource_name> To download data from presistent volume use: TBD","title":"Kubernetes tools cheat sheet"},{"location":"neptune/","text":"mrunner run experiments with neptune . Currently it is not possible to disable it. Authorization Method of authorization with neptune server depends on neptune version. For v1 credentials are stored in neptune global configuration file (by default ~/.neptune.yaml ). Example configuration: host: <neptune_v1_server> port: 443 username: <email> password: <password> For version v2 neptune account login command is used authorize and obtain OAuth2 tokens. More details on configuration may be found in v1.6 and v2 documentations. Internals details Tokens are stored (again depending on neptune-cli version): $HOME/.neptune_tokens/ for neptune-cli>=2.0.0,neptune-cli<=2.8.14 $HOME/.neptune/tokens/ for neptune-cli>=2.8.15 Required connection parameters/tokens are passed during remote execution using environment variables or attached as file to experiment archive. Tags Experiment related neptune tags may be set in 4 places: - fixed tags shall be placed in neptune.yaml file as tags key - fixed tags may be also placed in context as tags key - run related tags may be addtionally added with CLI --tags parameter - added tags programmatically to neptune context (TODO: add sample) mrunner run --config neptune.yaml \\ --tags \"grid_search_k-12-48\" --tags new_data \\ --requirements requirements.txt \\ --base_image python:3 experiment1.py -- --param1 1 Storage [TODO: describe difference between v1 and v2] Running neptune in mpirun/srun experiments [TODO: test it] Requirements overwriting in older versions There is issue with installation of other packages with neptune-cli<=2.8.8. If put some packages with conflicting requirements, it is observed that older version of packages may be installed if after installation of neptune-cli.","title":"neptune"},{"location":"neptune/#authorization","text":"Method of authorization with neptune server depends on neptune version. For v1 credentials are stored in neptune global configuration file (by default ~/.neptune.yaml ). Example configuration: host: <neptune_v1_server> port: 443 username: <email> password: <password> For version v2 neptune account login command is used authorize and obtain OAuth2 tokens. More details on configuration may be found in v1.6 and v2 documentations.","title":"Authorization"},{"location":"neptune/#internals-details","text":"Tokens are stored (again depending on neptune-cli version): $HOME/.neptune_tokens/ for neptune-cli>=2.0.0,neptune-cli<=2.8.14 $HOME/.neptune/tokens/ for neptune-cli>=2.8.15 Required connection parameters/tokens are passed during remote execution using environment variables or attached as file to experiment archive.","title":"Internals details"},{"location":"neptune/#tags","text":"Experiment related neptune tags may be set in 4 places: - fixed tags shall be placed in neptune.yaml file as tags key - fixed tags may be also placed in context as tags key - run related tags may be addtionally added with CLI --tags parameter - added tags programmatically to neptune context (TODO: add sample) mrunner run --config neptune.yaml \\ --tags \"grid_search_k-12-48\" --tags new_data \\ --requirements requirements.txt \\ --base_image python:3 experiment1.py -- --param1 1","title":"Tags"},{"location":"neptune/#storage","text":"[TODO: describe difference between v1 and v2]","title":"Storage"},{"location":"neptune/#running-neptune-in-mpirunsrun-experiments","text":"[TODO: test it]","title":"Running neptune in mpirun/srun experiments"},{"location":"neptune/#requirements-overwriting-in-older-versions","text":"There is issue with installation of other packages with neptune-cli<=2.8.8. If put some packages with conflicting requirements, it is observed that older version of packages may be installed if after installation of neptune-cli.","title":"Requirements overwriting in older versions"},{"location":"setup/","text":"mrunner is tested on python2.7 and python3.5, but newer versions of python3 shall also work. Additionally we recommend to install and use mrunner in virtualenv . To install it use following commands: shell pip install neptune-cli==1.6 pip install git+ssh://git@pascal-tower01.intra.codilime.com/ml-robotics/mrunner.git@develop Above sequence is related with neptune issues . Set some remote contexts and select active one Configure clients for at least one system: slurm kubernetes Remote context To avoid passing details on configuration of computation system, it is possible to store predefined configuration parameters. Each configuration is named and can be selected during experiment start or set by default: mrunner run foo.py -- --param1 2 # run with context defined in current_context config key mrunner --context plgrid.agents run foo.py -- --param1 2 mrunner --context plgrid.agents --config mrunner.yaml run foo.py -- --param1 2 # loads configuration from local file (instead of user configuration directory) Set of keys depends on type of remote context. For description of available keys go to proper sections (ex. slurm , kubernetes ). To manage contexts use context command. Example calls: mrunner context mrunner context add --name gke.sandbox --backend_type kubernetes \\ --registry_url https://gcr.io --storage /storage --resources \"tpu=1 cpu=4\" mrunner context edit gke.sandbox # opens editor with context parameters mrunner context set-active gke.sandbox mrunner context delete gke.sandbox mrunner context copy gke.sandbox gke.new mrunner --config mrunner.yaml context set-active gke.sandbox Example remote contexts': name: gke.sandbox type: kubernetes registry_url: https://gcr.io resources: cpu: 4 tpu: 1 neptune: true storage: /storage","title":"setup"},{"location":"setup/#remote-context","text":"To avoid passing details on configuration of computation system, it is possible to store predefined configuration parameters. Each configuration is named and can be selected during experiment start or set by default: mrunner run foo.py -- --param1 2 # run with context defined in current_context config key mrunner --context plgrid.agents run foo.py -- --param1 2 mrunner --context plgrid.agents --config mrunner.yaml run foo.py -- --param1 2 # loads configuration from local file (instead of user configuration directory) Set of keys depends on type of remote context. For description of available keys go to proper sections (ex. slurm , kubernetes ). To manage contexts use context command. Example calls: mrunner context mrunner context add --name gke.sandbox --backend_type kubernetes \\ --registry_url https://gcr.io --storage /storage --resources \"tpu=1 cpu=4\" mrunner context edit gke.sandbox # opens editor with context parameters mrunner context set-active gke.sandbox mrunner context delete gke.sandbox mrunner context copy gke.sandbox gke.new mrunner --config mrunner.yaml context set-active gke.sandbox Example remote contexts': name: gke.sandbox type: kubernetes registry_url: https://gcr.io resources: cpu: 4 tpu: 1 neptune: true storage: /storage","title":"Remote context"},{"location":"slurm/","text":"Read presentation from PLGrid Workshop to gain knowledge on slurm and PLGrid clusters. Setup slurm remote context keys for slurm Possible remote context keys: key req description example name R unique name of context which identifies him plgrid.plggluna.sandbox type R shall equal slurm slurm slurm_url R username and address of slurm cluster chnorris@pro.cyfronet.pl storage_dir R path to directory where neptune CLI will store data for experiment provenance (required even when neptune is disabled; may use env variables) /storage partition R request a specific slurm partition for the resource allocation plgrid-testing user_id R any, meaningful user id used to identify owner of experiment pz scratch_dir O subdirectories under $SCRATCH dir (default mrunner ) mrunner resources O defines resource limits for every experiment (by default no resource limits) {cpu: 4, gpu: 1, mem: 8G} neptune O enable/disable neptune (by default enabled) true modules_to_load O list of space separated additional slurm modules to load plgrid/tools/python/3.6.0 plgrid/tools/ffmpeg/3.2.2 after_module_load_ cmd O shell oneliner executed after slurm module load, before sourcing venv export PATH=/net/people/plghenrykm/anaconda2/bin:$PATH; source activate opensim-rl-2.7 venv O path to virtual environment; can be overwritten by CLI venv option '/net/people/plghenrykm/ppo_tpu/ppo_env time O Set a limit on the total run time of the job allocation. If the requested time limit exceeds the partition's time limit, the job will be left in a PENDING state (possibly indefinitely). (Used with sbatch flag) 3600000 ntasks O This option advises the slurm controller that job steps run within the allocation will launch a maximum of number tasks and to provide for sufficient resources. The default is one task per node, but note that the Slurm '--cpus-per-task' option will change this default. plgrid Filesystem: - /net/scratch - lustre filesystem meant for short term use (cleaned after some period of time? 1 month? number of files quota?) - $SCRATCH - your account scratch directory - $SCRATCH/mrunner - current default scratch directory for mrunner - /net/archive - lustre filesystem - $PLG_GROUPS_STORAGE - currently it points to /net/archive/groups - /net/people - NFS filesystem - $HOME - your home directory (it is in /net/people ) - Read best practices while using lustre filesystem (not exactly for plgrid cluster, but certainly shall be used during) Run experiment on slurm Available options specific for slurm cluster: key req description / additional information example config R path to neptune experiment configuration; mrunner uses i.a. project and experiment names, parameters list neptune.yaml base_image R name and tag of base docker image used to build experiment docker image python:3 requirements R path to requirements.txt file with python requirements requirements.txt Sample command call: mrunner run --config neptune.yaml \\ --tags \"grid_search_k-12-48\" --tags new_data \\ --requirements requirements.txt \\ --base_image python:3 experiment1.py -- --param1 1 Another example could be: mrunner --context gke.sandbox run --config neptune.yaml \\ --base_image python:3 \\ --requirements requirements.txt \\ -- experiment1.py -- --epochs 3 Notice (in both examples) that certain flags refer to the mrunner itself (eg. config, base_image) and others to experiment/script that we wish to run (eg. epochs, param1); the way these two sets are separated is relevant ('--'). Context is provided to mrunner before run . While running experiments on kubernetes, mrunner performs following steps: Prepares docker image based on provided in command line parameters see templates/Dockerfile.jinja2 file for details during build docker cache is used, so if there is no change in requirements.txt file, build shall be relatively fast If new image was generated tags it with timestamp and published in docker containers repository. Ensure kubernetes configuration (create resources if missing) namespace named after project name exists; see cluster namespaces section how to switch kubectl between them. persistent volume claim Generate kubernetes job - in fact your experiment","title":"slurm"},{"location":"slurm/#setup-slurm","text":"","title":"Setup slurm"},{"location":"slurm/#remote-context-keys-for-slurm","text":"Possible remote context keys: key req description example name R unique name of context which identifies him plgrid.plggluna.sandbox type R shall equal slurm slurm slurm_url R username and address of slurm cluster chnorris@pro.cyfronet.pl storage_dir R path to directory where neptune CLI will store data for experiment provenance (required even when neptune is disabled; may use env variables) /storage partition R request a specific slurm partition for the resource allocation plgrid-testing user_id R any, meaningful user id used to identify owner of experiment pz scratch_dir O subdirectories under $SCRATCH dir (default mrunner ) mrunner resources O defines resource limits for every experiment (by default no resource limits) {cpu: 4, gpu: 1, mem: 8G} neptune O enable/disable neptune (by default enabled) true modules_to_load O list of space separated additional slurm modules to load plgrid/tools/python/3.6.0 plgrid/tools/ffmpeg/3.2.2 after_module_load_ cmd O shell oneliner executed after slurm module load, before sourcing venv export PATH=/net/people/plghenrykm/anaconda2/bin:$PATH; source activate opensim-rl-2.7 venv O path to virtual environment; can be overwritten by CLI venv option '/net/people/plghenrykm/ppo_tpu/ppo_env time O Set a limit on the total run time of the job allocation. If the requested time limit exceeds the partition's time limit, the job will be left in a PENDING state (possibly indefinitely). (Used with sbatch flag) 3600000 ntasks O This option advises the slurm controller that job steps run within the allocation will launch a maximum of number tasks and to provide for sufficient resources. The default is one task per node, but note that the Slurm '--cpus-per-task' option will change this default.","title":"remote context keys for slurm"},{"location":"slurm/#plgrid","text":"Filesystem: - /net/scratch - lustre filesystem meant for short term use (cleaned after some period of time? 1 month? number of files quota?) - $SCRATCH - your account scratch directory - $SCRATCH/mrunner - current default scratch directory for mrunner - /net/archive - lustre filesystem - $PLG_GROUPS_STORAGE - currently it points to /net/archive/groups - /net/people - NFS filesystem - $HOME - your home directory (it is in /net/people ) - Read best practices while using lustre filesystem (not exactly for plgrid cluster, but certainly shall be used during)","title":"plgrid"},{"location":"slurm/#run-experiment-on-slurm","text":"Available options specific for slurm cluster: key req description / additional information example config R path to neptune experiment configuration; mrunner uses i.a. project and experiment names, parameters list neptune.yaml base_image R name and tag of base docker image used to build experiment docker image python:3 requirements R path to requirements.txt file with python requirements requirements.txt Sample command call: mrunner run --config neptune.yaml \\ --tags \"grid_search_k-12-48\" --tags new_data \\ --requirements requirements.txt \\ --base_image python:3 experiment1.py -- --param1 1 Another example could be: mrunner --context gke.sandbox run --config neptune.yaml \\ --base_image python:3 \\ --requirements requirements.txt \\ -- experiment1.py -- --epochs 3 Notice (in both examples) that certain flags refer to the mrunner itself (eg. config, base_image) and others to experiment/script that we wish to run (eg. epochs, param1); the way these two sets are separated is relevant ('--'). Context is provided to mrunner before run . While running experiments on kubernetes, mrunner performs following steps: Prepares docker image based on provided in command line parameters see templates/Dockerfile.jinja2 file for details during build docker cache is used, so if there is no change in requirements.txt file, build shall be relatively fast If new image was generated tags it with timestamp and published in docker containers repository. Ensure kubernetes configuration (create resources if missing) namespace named after project name exists; see cluster namespaces section how to switch kubectl between them. persistent volume claim Generate kubernetes job - in fact your experiment","title":"Run experiment on slurm"},{"location":"tips/","text":"good practices while using kubernetes you can easily clean-up unnecessary jobs and pods by running this command: commandline kubectl delete job <job-id-here> Do not delete pvc s or namespace 's unless you're sure you're want that, otherwise you may accidentally delete the storage used by somebody's else job. common errors install locally and remotely differnt major versions of neptune. As there is difference in neptune.yaml semantic between neptune-cli v1 an v2 parse errors are rised. It may looks like: File \"/usr/local/lib/python3.5/dist-packages/pykwalify/core.py\", line 209, in _validate self._validate_sequence(value, rule, path, done=None) File \"/usr/local/lib/python3.5/dist-packages/pykwalify/core.py\", line 288, in _validate_sequence raise NotSequenceError(u\"Value: {} is not of a sequence type\".format(value)) pykwalify.errors.NotSequenceError: <NotSequenceError: error code 7: Value: {'param1': 0.985, 'param2': 1} is not of a sequence type: Path: '/'>","title":"tips"},{"location":"tips/#good-practices","text":"while using kubernetes you can easily clean-up unnecessary jobs and pods by running this command: commandline kubectl delete job <job-id-here> Do not delete pvc s or namespace 's unless you're sure you're want that, otherwise you may accidentally delete the storage used by somebody's else job.","title":"good practices"},{"location":"tips/#common-errors","text":"install locally and remotely differnt major versions of neptune. As there is difference in neptune.yaml semantic between neptune-cli v1 an v2 parse errors are rised. It may looks like: File \"/usr/local/lib/python3.5/dist-packages/pykwalify/core.py\", line 209, in _validate self._validate_sequence(value, rule, path, done=None) File \"/usr/local/lib/python3.5/dist-packages/pykwalify/core.py\", line 288, in _validate_sequence raise NotSequenceError(u\"Value: {} is not of a sequence type\".format(value)) pykwalify.errors.NotSequenceError: <NotSequenceError: error code 7: Value: {'param1': 0.985, 'param2': 1} is not of a sequence type: Path: '/'>","title":"common errors"}]}